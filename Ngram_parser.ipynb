{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##NLTK based ngram and POS-ngram parser\n",
    "\n",
    "###Requirements:\n",
    "    * NLTK\n",
    "    * NLTK downloads:\n",
    "<pre><code>\n",
    "\\#in terminal type\n",
    "import nltk\n",
    "nltk.download() \n",
    "</code></pre>\n",
    "A pop up window appears. In the window choose:\n",
    "    * Models => Treebanks Part of Speech Tagger, Treebank Part of Speech Tagger (Maximum entropy), Punkt Tokenizer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk     #download NLTK http://www.nltk.org/\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle') #Add a tokanizer packege with import nltk \\n nltk.download()\n",
    "lmtzr = WordNetLemmatizer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizers\n",
    "# Given a sentence returns a list of ngrams\n",
    "# Note: requires local sentence parsing\n",
    "table = string.maketrans(\"\",\"\")\n",
    "\n",
    "def get_word_ngrams1(text, n):\n",
    "    ngram_list = []\n",
    "    word_list = [lmtzr.lemmatize(word) for word in text.lower().translate(table, string.punctuation).split()]\n",
    "    padding = [\"<s>\"] * (n -1)\n",
    "    word_list = padding + word_list + padding\n",
    "    for i in range(len(word_list) - (n-1)):\n",
    "        ngram_list.append(\" \".join(word_list[i:i+(n)]))\n",
    "    return ngram_list\n",
    "    \n",
    "# Get word unigrams\n",
    "def get_pos_ngrams1(text, n):\n",
    "    pos_list = []\n",
    "    word_list = [lmtzr.lemmatize(word) for word in text.lower().translate(table, string.punctuation).split()]\n",
    "    padding = [\"<s>\"] * (n -1)\n",
    "    pos_list_temp = [ pair[1] for pair in nltk.pos_tag(word_list)] # uncomment this for unigram POS\n",
    "    pos_list_temp = padding + pos_list + padding\n",
    "    for i in range(len(pos_list_temp) - (n-1)):\n",
    "        pos_list.append(\" \".join(pos_list[i:i+(n)]))\n",
    "    return pos_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guys, shall we meet to discuss next steps?\n",
      "Unigrams:  ['guy', 'shall', 'we', 'meet', 'to', 'discus', 'next', 'step']\n",
      "Bigrams:  ['<s> guy', 'guy shall', 'shall we', 'we meet', 'meet to', 'to discus', 'discus next', 'next step', 'step <s>']\n",
      "Part of speech bigrams:  [''] \n",
      "\n",
      "\n",
      "Anyone interested to meet on Friday?\n",
      "Unigrams:  ['anyone', 'interested', 'to', 'meet', 'on', 'friday']\n",
      "Bigrams:  ['<s> anyone', 'anyone interested', 'interested to', 'to meet', 'meet on', 'on friday', 'friday <s>']\n",
      "Part of speech bigrams:  [''] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Guys, shall we meet to discuss next steps? Anyone interested to meet on Friday? \"\n",
    "\n",
    "sentences = [sent for sent in sent_detector.tokenize(text.strip())]\n",
    "for sent in sentences:\n",
    "    print sent\n",
    "    print \"Unigrams: \",get_word_ngrams1(sent, 1)\n",
    "    print \"Bigrams: \", get_word_ngrams1(sent, 2)\n",
    "    print \"Part of speech bigrams: \", get_pos_ngrams1(sent, 2), \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
